{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ds-cs-N423a.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DamiSoh/DE-code-study/blob/main/ds_cs_N423a_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBQsZEJmubLs"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 1 / Assingment 3*\n",
        "\n",
        "---\n",
        "# Neural Network Framework (Keras)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN5Wzlub62DZ"
      },
      "source": [
        "\n",
        "## 기본과제\n",
        "### 케라스 라이브러리를 사용하여 Multi-Layer Perceptron 모델을 CIFAR100 데이터에 적용해보세요.\n",
        "\n",
        "- 시드를 고정하십시오.\n",
        "- 데이터를 Noramlized 해줍니다. \n",
        "- 케라스에서 모델은 다음과 같이 고정합니다. \n",
        "- 은닉층의 활성함수는 ReLU를 사용합니다.\n",
        "- 단계별로 오늘 배운 규제방법을 적용해봅니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBPLbaggP52G"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import os\n",
        "import random"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7nHEuYmd-p6"
      },
      "source": [
        "### 1) Base model을 제작합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T_3XkVRY2xw"
      },
      "source": [
        "# seed를 고정합니다.\n",
        "\n",
        "random.seed(1)\n",
        "np.random.seed(1)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(1)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = str(1)\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "# 데이터 불러오기\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTRZ1izIAo0I",
        "outputId": "6613cf8e-eb2b-4af3-ec77-0db0169fd3f4"
      },
      "source": [
        "print(X_train.max(), X_train.shape, X_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "255 (50000, 32, 32, 3) (10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2BVYcXSAnDM"
      },
      "source": [
        "# 정규화(전처리)\n",
        "### Your Code Here ###\n",
        "\n",
        "X_train = X_train / 255.\n",
        "X_test = X_test /255.\n",
        "\n",
        "# 변수 설정을 따로 하는 방법을 적용하기 위한 코드입니다. \n",
        "batch_size = 100\n",
        "epochs_max = 20\n",
        "\n",
        "# model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(32,32,3)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# 컴파일 단계, 옵티마이저와 손실함수, 측정지표를 연결해서 계산 그래프를 구성함\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "results = model.fit(X_train, y_train, epochs=epochs_max, batch_size=batch_size, verbose=1, validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdxJ5AnieUxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9c055a8-834c-41c3-9d72-71d491fc5abf"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=1) \n",
        "\n",
        "#과제(정규화 O, verbose = 1): Accuracy: 0.2095\n",
        "#정규화 X : Accuracy: 0.0100\n",
        "#verbose= 2 : Accuracy: 0.2095\n",
        "#verbose 학습 단위 (?) 0,1 or 2"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 3.3331 - accuracy: 0.2095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DX7-Gqn_M-8"
      },
      "source": [
        "### 2) + Weight Decay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBQks0_rZWa9"
      },
      "source": [
        "# seed를 고정합니다.\n",
        "random.seed(1)\n",
        "np.random.seed(1)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(1)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = str(1)\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "# 데이터 불러오기\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# 정규화(전처리)\n",
        "X_train = X_train / 255.\n",
        "X_test = X_test /255.\n",
        "\n",
        "# 변수 설정을 따로 하는 방법을 적용하기 위한 코드입니다. \n",
        "batch_size = 100\n",
        "epochs_max = 20\n",
        "\n",
        "# model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten(input_shape=(32,32,3)))\n",
        "\n",
        "model.add(Dense(128, activation='relu', \n",
        "                kernel_regularizer=regularizers.l2(0.00001), ###L2 regularization / param = 0.00001###,   \n",
        "                activity_regularizer=regularizers.l1(0.00001)))###L1 regularization / param = 0.00001###))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# 컴파일 단계, 옵티마이저와 손실함수, 측정지표를 연결해서 계산 그래프를 구성함\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "results = model.fit(X_train, y_train, epochs=epochs_max, batch_size=batch_size, verbose=1, validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHns5cEr_M--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9538a74e-e5a3-4f90-d132-ea987ed8b24d"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=1)\n",
        "\n",
        "#과제 정확도 : 0.2174\n",
        "#kernel_regularizer=regularizers.l2(0.5)변경시 : 0.1000"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 3.3089 - accuracy: 0.2174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yQeUcY8fp4x"
      },
      "source": [
        "### 3) + Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_B_mosCZ_Ds"
      },
      "source": [
        "# seed를 고정합니다.\n",
        "random.seed(1)\n",
        "np.random.seed(1)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(1)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = str(1)\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "# 데이터 불러오기\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# 정규화(전처리)\n",
        "X_train = X_train / 255.\n",
        "X_test = X_test /255.\n",
        "\n",
        "# 변수 설정을 따로 하는 방법을 적용하기 위한 코드입니다. \n",
        "batch_size = 100\n",
        "epochs_max = 20\n",
        "\n",
        "# model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(32,32,3)))\n",
        "model.add(Dense(128*1.1, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# 컴파일 단계, 옵티마이저와 손실함수, 측정지표를 연결해서 계산 그래프를 구성함\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "results = model.fit(X_train, y_train, epochs=epochs_max, batch_size=batch_size, verbose=1, validation_data=(X_test,y_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFcSErMHT4j5",
        "outputId": "656fdd53-474b-4fd6-c1f6-c829b94a0ab4"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=1)\n",
        "\n",
        "#과제: 0.1990\n",
        "#dropout 0.3: 0.1044"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 3.3866 - accuracy: 0.1990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3RoevKkC27v"
      },
      "source": [
        "### 문항 4) + Early Stopping\n",
        "\n",
        "1. Early Stopping을 적용해봅시다. 멈추는 기준을 `val_loss(검증 데이터셋의 loss 값)`로 하고 loss가 Best 값보다 5번 높아질 때 Stop 하도록 설정합니다.\n",
        "\n",
        "2. Best 모델을 저장해봅시다. Best 모델 역시 멈추는 기준을 `val_loss(검증 데이터셋의 loss 값)`로 하고 `save_best_only=True, save_weights_only=True` 로 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjj4th3oLjgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c48fb44-0f9f-48a0-9e6c-4806680d6bd0"
      },
      "source": [
        "# seed를 고정합니다.\n",
        "random.seed(1)\n",
        "np.random.seed(1)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(1)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = str(1)\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "\n",
        "# 데이터 불러오기\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "\n",
        "\n",
        "# 정규화(전처리)\n",
        "X_train = X_train / 255.\n",
        "X_test = X_test /255.\n",
        "\n",
        "\n",
        "\n",
        "# 학습시킨 데이터를 저장시키기 위한 코드입니다. \n",
        "checkpoint_filepath = \"FMbest.hdf5\"\n",
        "\n",
        "\n",
        "# 변수 설정을 따로 하는 방법을 적용하기 위한 코드입니다. \n",
        "batch_size = 100\n",
        "epochs_max = 50\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(32,32,3)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# 컴파일 단계, 옵티마이저와 손실함수, 측정지표를 연결해서 계산 그래프를 구성함\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "                  \n",
        "# early stopping\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1)\n",
        "\n",
        "# Validation Set을 기준으로 가장 최적의 모델을 찾기\n",
        "# save_best = tf.keras.callbacks.ModelCheckpoint(\n",
        "#     filepath=checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
        "#     save_weights_only=True, mode='auto', save_freq='epoch', options=None)\n",
        "\n",
        "save_best = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor = 'val_loss',\n",
        "    verbose = 1,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,mode='auto', save_freq='epoch', options=None\n",
        ")\n",
        "\n",
        "\n",
        "# model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs_max, verbose=1, \n",
        "#           validation_data=(X_test,y_test), \n",
        "#           callbacks=[early_stop, save_best])\n",
        "\n",
        "results = model.fit(X_train, y_train, batch_size = batch_size, epochs=epochs_max, verbose=1,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[early_stop, save_best])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 4.1250 - accuracy: 0.0702 - val_loss: 3.8698 - val_accuracy: 0.1068\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.86977, saving model to FMbest.hdf5\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.7575 - accuracy: 0.1223 - val_loss: 3.7199 - val_accuracy: 0.1331\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.86977 to 3.71993, saving model to FMbest.hdf5\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 3.6322 - accuracy: 0.1446 - val_loss: 3.6934 - val_accuracy: 0.1442\n",
            "\n",
            "Epoch 00003: val_loss improved from 3.71993 to 3.69343, saving model to FMbest.hdf5\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 3.5500 - accuracy: 0.1588 - val_loss: 3.5947 - val_accuracy: 0.1592\n",
            "\n",
            "Epoch 00004: val_loss improved from 3.69343 to 3.59470, saving model to FMbest.hdf5\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.4954 - accuracy: 0.1698 - val_loss: 3.5242 - val_accuracy: 0.1731\n",
            "\n",
            "Epoch 00005: val_loss improved from 3.59470 to 3.52423, saving model to FMbest.hdf5\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.4336 - accuracy: 0.1801 - val_loss: 3.5019 - val_accuracy: 0.1724\n",
            "\n",
            "Epoch 00006: val_loss improved from 3.52423 to 3.50194, saving model to FMbest.hdf5\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.3962 - accuracy: 0.1884 - val_loss: 3.4911 - val_accuracy: 0.1778\n",
            "\n",
            "Epoch 00007: val_loss improved from 3.50194 to 3.49112, saving model to FMbest.hdf5\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.3572 - accuracy: 0.1946 - val_loss: 3.4645 - val_accuracy: 0.1847\n",
            "\n",
            "Epoch 00008: val_loss improved from 3.49112 to 3.46448, saving model to FMbest.hdf5\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.3278 - accuracy: 0.1997 - val_loss: 3.4580 - val_accuracy: 0.1843\n",
            "\n",
            "Epoch 00009: val_loss improved from 3.46448 to 3.45805, saving model to FMbest.hdf5\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 3.3027 - accuracy: 0.2049 - val_loss: 3.3787 - val_accuracy: 0.2080\n",
            "\n",
            "Epoch 00010: val_loss improved from 3.45805 to 3.37868, saving model to FMbest.hdf5\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 3.2705 - accuracy: 0.2104 - val_loss: 3.3671 - val_accuracy: 0.2027\n",
            "\n",
            "Epoch 00011: val_loss improved from 3.37868 to 3.36706, saving model to FMbest.hdf5\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 3.2428 - accuracy: 0.2156 - val_loss: 3.3678 - val_accuracy: 0.2000\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 3.36706\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.2196 - accuracy: 0.2207 - val_loss: 3.3916 - val_accuracy: 0.1977\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 3.36706\n",
            "Epoch 14/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.2036 - accuracy: 0.2222 - val_loss: 3.3354 - val_accuracy: 0.2143\n",
            "\n",
            "Epoch 00014: val_loss improved from 3.36706 to 3.33539, saving model to FMbest.hdf5\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 3.1894 - accuracy: 0.2249 - val_loss: 3.3553 - val_accuracy: 0.2125\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 3.33539\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.1778 - accuracy: 0.2256 - val_loss: 3.3481 - val_accuracy: 0.2062\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 3.33539\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.1577 - accuracy: 0.2307 - val_loss: 3.3338 - val_accuracy: 0.2099\n",
            "\n",
            "Epoch 00017: val_loss improved from 3.33539 to 3.33385, saving model to FMbest.hdf5\n",
            "Epoch 18/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.1463 - accuracy: 0.2302 - val_loss: 3.3203 - val_accuracy: 0.2129\n",
            "\n",
            "Epoch 00018: val_loss improved from 3.33385 to 3.32032, saving model to FMbest.hdf5\n",
            "Epoch 19/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 3.1348 - accuracy: 0.2332 - val_loss: 3.3429 - val_accuracy: 0.2095\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 3.32032\n",
            "Epoch 20/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 3.1245 - accuracy: 0.2346 - val_loss: 3.3331 - val_accuracy: 0.2095\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 3.32032\n",
            "Epoch 21/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.1156 - accuracy: 0.2357 - val_loss: 3.3198 - val_accuracy: 0.2110\n",
            "\n",
            "Epoch 00021: val_loss improved from 3.32032 to 3.31982, saving model to FMbest.hdf5\n",
            "Epoch 22/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 3.1055 - accuracy: 0.2372 - val_loss: 3.3527 - val_accuracy: 0.2054\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 3.31982\n",
            "Epoch 23/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.0922 - accuracy: 0.2423 - val_loss: 3.3388 - val_accuracy: 0.2077\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 3.31982\n",
            "Epoch 24/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 3.0889 - accuracy: 0.2397 - val_loss: 3.3427 - val_accuracy: 0.2087\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 3.31982\n",
            "Epoch 25/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.0854 - accuracy: 0.2430 - val_loss: 3.3223 - val_accuracy: 0.2129\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 3.31982\n",
            "Epoch 26/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 3.0737 - accuracy: 0.2432 - val_loss: 3.3207 - val_accuracy: 0.2157\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 3.31982\n",
            "Epoch 00026: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk3GSXbfUI91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70746f05-9fff-42c7-cb66-42720fe95523"
      },
      "source": [
        "# 학습된 모델을 이용하여 테스트하는 코드\n",
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=1)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 3.3207 - accuracy: 0.2157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyz7CrMIUNJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d384c8c-2e63-454d-b0c4-61555cfc8a04"
      },
      "source": [
        "model.load_weights(checkpoint_filepath)\n",
        "\n",
        "# best model을 이용한 테스트 데이터 예측 정확도 재확인 코드\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 3.3198 - accuracy: 0.2110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybHZiZAjba8C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}